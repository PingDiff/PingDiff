{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation d’un algorithme de points intérieurs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Les algorithmes de points intérieurs sont des algorithmes qui permettent d’optimiser des problèmes linéaires et non linéaires avec contraintes. Ils sont dérivés de la méthode des points extérieures (ou des ellipses) qui avait pour but d’optimiser des problèmes non linéaires avec contraintes, mais qui avait une trop grande complexité en espace(bits pour stocker).\n",
    "Den Hertog (1994) a classé les méthodes de points intérieurs en quatre catégories :\n",
    "- Méthodes de chemin central\n",
    "- Méthodes affines et mise à l’échelle\n",
    "- Méthodes projectives avec potentiel\n",
    "- Méthodes affines avec potentiel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Au fil de ce notebook, nous porterons notre attention plus particulièrement sur les\n",
    "méthodes de chemin central ou critique, et plus précisément de barrière logarithmique, et son\n",
    "implémentation en langage Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import *\n",
    "def deriveepolynome(liste):\n",
    "    d = [Decimal('0')]*(len(liste)-1)\n",
    "    for i in range(len(d)):\n",
    "        d[i] += Decimal(int(liste[i]) * (len(liste) - i - 1))\n",
    "    return d\n",
    "def deriveepartielle(liste):\n",
    "    dp = []\n",
    "    for j in range(len(liste)):\n",
    "        dp.append(deriveepolynome(liste[j]))\n",
    "    return dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultat(v, polynome):\n",
    "    r= Decimal(0)\n",
    "    deg=(len(polynome))\n",
    "    for k in range(int(deg)):\n",
    "        if v!=0:\n",
    "            r += polynome[k]*(v**(deg-k-1))\n",
    "        else:\n",
    "            if deg-k-1==0:\n",
    "                r += polynome[k]\n",
    "            else:\n",
    "                r+=0\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def somme(x, contrainte):\n",
    "    s=Decimal('0')\n",
    "    for i in range(len(x)):\n",
    "        s+= Decimal(resultat(x[i], contrainte[i]))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le principe général de cette méthode revient à transformer le programme contraint en un programme sans contraintes, ici à l’aide d’un fonction logarithmique, qui par\n",
    "la définition du logarithme, défini un nouveau domaine de définition pour la fonction objectif à minimiser. L’existence d’une solution au problème repose essentiellement\n",
    "sur un critère : l’existence au moins d’un point appartenant au domaine de définition de la fonction objectif obtenue. Cette fonction ext dite donc pénalisée. Dans ce but,\n",
    "nous réécrivons l’ensemble de toutes nos contraintes sous formes d’inéquations de supériorité (le domaine de définition du log étant R∗+ )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contraintelineaire(x, fonctob, listcont):\n",
    "    u=Decimal(0.01)\n",
    "    d=deriveepartielle(fonctob)\n",
    "    for j in range(len(listcont)):\n",
    "        s=listcont[j][len(x)]\n",
    "        for i in range(len(x)):\n",
    "            s+=x[i]*listcont[j][i]\n",
    "        if s<=0:\n",
    "            for k in range(len(x)):\n",
    "                if (listcont[j][k]!=0):\n",
    "                    d[k]=[0]*len(x)\n",
    "        \n",
    "        else:\n",
    "            for i in range(len(x)):\n",
    "                d[i][len(d[i])-1]-=u*listcont[j][i]/s\n",
    "                \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons ainsi le gradient de notre fonction pénalisée:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x, fonctobj, listcont):\n",
    "    grad = []\n",
    "    for i in range(len(x)):\n",
    "        grad.append(resultat(x[i],contraintelineaire(x, fonctobj, listcont)[i]))\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois notre programme sans contraintes obtenu, on applique un algorithme de gradient descendant qui nous permet de nous rapprocher du minimum local (dans le domaine de définition de la fonction pénalisée), et c’est ainsi que nous arrivons à obtenir une solution optimale de notre programme (linéaire ou non linéaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def methodeDescente(X0, obj, lcont):\n",
    "    X = X0\n",
    "  \n",
    "    gX = gradient(X, obj,lcont)\n",
    "    \n",
    "    alpha = Decimal(0.12)\n",
    "    iterations=0\n",
    "    while numpy.linalg.norm(gX) > Decimal('0.01'):\n",
    "        if iterations > 500:\n",
    "            break\n",
    "        elif (gX==[0]*len(X0)):\n",
    "            break\n",
    "        else:\n",
    "            alpha*=(1-alpha)\n",
    "            iterations +=1\n",
    "            for j in range(len(lcont)):\n",
    "                for i in range(len(X0)):\n",
    "                    X[i] -= alpha * gX[i]\n",
    "                    gX = gradient(X, obj,lcont)\n",
    "                \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etude de la convergence de l'algorithme\n",
    "La question de convergence n’est pas posée et théorie, mais en pratique c’est une question différente. Elle dépend du pas du gradient utilisé, ainsi que de la puissance de calcul de la machine. Il faut que le pas associé au gradient soit assez petit afin d’éviter un effet \"pendule\" qui ferait que le programme diverge et ne s’arrête jamais. Nous avons aussi pensé à ajouter un compteur qui retourne un résultat au bout d’un certain nombre d’itérations (ici 500), qui certes réduit la précision du programme, mais garanti au moins l’obtention d’une solution optimale au pas du gradient près."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
